{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../rudeus')\n",
    "import pandas as pd\n",
    "from machine_learning.clf_models import ClfModel\n",
    "from machine_learning.preprocessing import random_under_sampling_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_0</th>\n",
       "      <th>p_1</th>\n",
       "      <th>p_2</th>\n",
       "      <th>p_3</th>\n",
       "      <th>p_4</th>\n",
       "      <th>p_5</th>\n",
       "      <th>p_6</th>\n",
       "      <th>p_7</th>\n",
       "      <th>p_8</th>\n",
       "      <th>p_9</th>\n",
       "      <th>...</th>\n",
       "      <th>p_503</th>\n",
       "      <th>p_504</th>\n",
       "      <th>p_505</th>\n",
       "      <th>p_506</th>\n",
       "      <th>p_507</th>\n",
       "      <th>p_508</th>\n",
       "      <th>p_509</th>\n",
       "      <th>p_510</th>\n",
       "      <th>p_511</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.051961</td>\n",
       "      <td>-0.109073</td>\n",
       "      <td>0.026836</td>\n",
       "      <td>-0.076748</td>\n",
       "      <td>0.109241</td>\n",
       "      <td>0.032815</td>\n",
       "      <td>-0.006516</td>\n",
       "      <td>-0.060004</td>\n",
       "      <td>-0.036764</td>\n",
       "      <td>-0.033473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082769</td>\n",
       "      <td>-0.032394</td>\n",
       "      <td>-0.036015</td>\n",
       "      <td>0.012536</td>\n",
       "      <td>0.043216</td>\n",
       "      <td>0.084375</td>\n",
       "      <td>0.007837</td>\n",
       "      <td>0.069794</td>\n",
       "      <td>-0.044134</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.032315</td>\n",
       "      <td>-0.122054</td>\n",
       "      <td>-0.010417</td>\n",
       "      <td>-0.071897</td>\n",
       "      <td>0.109930</td>\n",
       "      <td>0.055475</td>\n",
       "      <td>0.002491</td>\n",
       "      <td>-0.050859</td>\n",
       "      <td>-0.043207</td>\n",
       "      <td>-0.031467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089238</td>\n",
       "      <td>-0.022887</td>\n",
       "      <td>-0.037875</td>\n",
       "      <td>0.013370</td>\n",
       "      <td>0.073821</td>\n",
       "      <td>0.096903</td>\n",
       "      <td>0.017133</td>\n",
       "      <td>0.064631</td>\n",
       "      <td>-0.039452</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.041239</td>\n",
       "      <td>-0.128768</td>\n",
       "      <td>0.013445</td>\n",
       "      <td>-0.089572</td>\n",
       "      <td>0.113357</td>\n",
       "      <td>0.028909</td>\n",
       "      <td>-0.003931</td>\n",
       "      <td>-0.059228</td>\n",
       "      <td>-0.044582</td>\n",
       "      <td>-0.015745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057286</td>\n",
       "      <td>-0.021680</td>\n",
       "      <td>-0.040389</td>\n",
       "      <td>0.014894</td>\n",
       "      <td>0.037244</td>\n",
       "      <td>0.083684</td>\n",
       "      <td>0.005021</td>\n",
       "      <td>0.065194</td>\n",
       "      <td>-0.036202</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.053598</td>\n",
       "      <td>-0.126727</td>\n",
       "      <td>0.013942</td>\n",
       "      <td>-0.089992</td>\n",
       "      <td>0.106270</td>\n",
       "      <td>0.019663</td>\n",
       "      <td>-0.009753</td>\n",
       "      <td>-0.045075</td>\n",
       "      <td>-0.045403</td>\n",
       "      <td>-0.019771</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064901</td>\n",
       "      <td>-0.031808</td>\n",
       "      <td>-0.035478</td>\n",
       "      <td>0.020381</td>\n",
       "      <td>0.035428</td>\n",
       "      <td>0.084140</td>\n",
       "      <td>0.008325</td>\n",
       "      <td>0.061186</td>\n",
       "      <td>-0.041064</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.055171</td>\n",
       "      <td>-0.123368</td>\n",
       "      <td>0.010215</td>\n",
       "      <td>-0.087683</td>\n",
       "      <td>0.107859</td>\n",
       "      <td>0.021741</td>\n",
       "      <td>-0.003519</td>\n",
       "      <td>-0.051125</td>\n",
       "      <td>-0.038727</td>\n",
       "      <td>-0.013142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067381</td>\n",
       "      <td>-0.025004</td>\n",
       "      <td>-0.037318</td>\n",
       "      <td>0.013757</td>\n",
       "      <td>0.041707</td>\n",
       "      <td>0.090888</td>\n",
       "      <td>0.021773</td>\n",
       "      <td>0.070574</td>\n",
       "      <td>-0.041105</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>-0.047186</td>\n",
       "      <td>-0.126568</td>\n",
       "      <td>0.016551</td>\n",
       "      <td>-0.091217</td>\n",
       "      <td>0.114245</td>\n",
       "      <td>0.028997</td>\n",
       "      <td>-0.011451</td>\n",
       "      <td>-0.054338</td>\n",
       "      <td>-0.046695</td>\n",
       "      <td>-0.021423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071683</td>\n",
       "      <td>-0.026062</td>\n",
       "      <td>-0.039263</td>\n",
       "      <td>0.015930</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.090228</td>\n",
       "      <td>0.004987</td>\n",
       "      <td>0.065474</td>\n",
       "      <td>-0.042609</td>\n",
       "      <td>double</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>-0.051686</td>\n",
       "      <td>-0.128937</td>\n",
       "      <td>0.017885</td>\n",
       "      <td>-0.089340</td>\n",
       "      <td>0.111332</td>\n",
       "      <td>0.024499</td>\n",
       "      <td>-0.011107</td>\n",
       "      <td>-0.054856</td>\n",
       "      <td>-0.046236</td>\n",
       "      <td>-0.017079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071391</td>\n",
       "      <td>-0.027886</td>\n",
       "      <td>-0.037365</td>\n",
       "      <td>0.019784</td>\n",
       "      <td>0.049307</td>\n",
       "      <td>0.091884</td>\n",
       "      <td>0.014374</td>\n",
       "      <td>0.066112</td>\n",
       "      <td>-0.041239</td>\n",
       "      <td>double</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>-0.041520</td>\n",
       "      <td>-0.126039</td>\n",
       "      <td>0.007327</td>\n",
       "      <td>-0.090880</td>\n",
       "      <td>0.113951</td>\n",
       "      <td>0.031531</td>\n",
       "      <td>-0.010603</td>\n",
       "      <td>-0.054147</td>\n",
       "      <td>-0.047652</td>\n",
       "      <td>-0.024619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071534</td>\n",
       "      <td>-0.028025</td>\n",
       "      <td>-0.037676</td>\n",
       "      <td>0.016719</td>\n",
       "      <td>0.061040</td>\n",
       "      <td>0.093330</td>\n",
       "      <td>0.009919</td>\n",
       "      <td>0.064024</td>\n",
       "      <td>-0.042506</td>\n",
       "      <td>double</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>-0.046474</td>\n",
       "      <td>-0.127358</td>\n",
       "      <td>-0.004217</td>\n",
       "      <td>-0.073223</td>\n",
       "      <td>0.108792</td>\n",
       "      <td>0.039449</td>\n",
       "      <td>-0.004596</td>\n",
       "      <td>-0.049178</td>\n",
       "      <td>-0.044158</td>\n",
       "      <td>-0.014196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086611</td>\n",
       "      <td>-0.018506</td>\n",
       "      <td>-0.027007</td>\n",
       "      <td>0.024811</td>\n",
       "      <td>0.059834</td>\n",
       "      <td>0.097593</td>\n",
       "      <td>0.028478</td>\n",
       "      <td>0.077590</td>\n",
       "      <td>-0.045125</td>\n",
       "      <td>double</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>-0.043099</td>\n",
       "      <td>-0.142669</td>\n",
       "      <td>0.023720</td>\n",
       "      <td>-0.088778</td>\n",
       "      <td>0.103328</td>\n",
       "      <td>0.024288</td>\n",
       "      <td>-0.011344</td>\n",
       "      <td>-0.062268</td>\n",
       "      <td>-0.041151</td>\n",
       "      <td>-0.007892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073401</td>\n",
       "      <td>-0.014165</td>\n",
       "      <td>-0.040095</td>\n",
       "      <td>0.023925</td>\n",
       "      <td>0.065251</td>\n",
       "      <td>0.095360</td>\n",
       "      <td>0.009302</td>\n",
       "      <td>0.068400</td>\n",
       "      <td>-0.043873</td>\n",
       "      <td>double</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1233 rows Ã— 513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           p_0       p_1       p_2       p_3       p_4       p_5       p_6  \\\n",
       "0    -0.051961 -0.109073  0.026836 -0.076748  0.109241  0.032815 -0.006516   \n",
       "1    -0.032315 -0.122054 -0.010417 -0.071897  0.109930  0.055475  0.002491   \n",
       "2    -0.041239 -0.128768  0.013445 -0.089572  0.113357  0.028909 -0.003931   \n",
       "3    -0.053598 -0.126727  0.013942 -0.089992  0.106270  0.019663 -0.009753   \n",
       "4    -0.055171 -0.123368  0.010215 -0.087683  0.107859  0.021741 -0.003519   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1228 -0.047186 -0.126568  0.016551 -0.091217  0.114245  0.028997 -0.011451   \n",
       "1229 -0.051686 -0.128937  0.017885 -0.089340  0.111332  0.024499 -0.011107   \n",
       "1230 -0.041520 -0.126039  0.007327 -0.090880  0.113951  0.031531 -0.010603   \n",
       "1231 -0.046474 -0.127358 -0.004217 -0.073223  0.108792  0.039449 -0.004596   \n",
       "1232 -0.043099 -0.142669  0.023720 -0.088778  0.103328  0.024288 -0.011344   \n",
       "\n",
       "           p_7       p_8       p_9  ...     p_503     p_504     p_505  \\\n",
       "0    -0.060004 -0.036764 -0.033473  ...  0.082769 -0.032394 -0.036015   \n",
       "1    -0.050859 -0.043207 -0.031467  ...  0.089238 -0.022887 -0.037875   \n",
       "2    -0.059228 -0.044582 -0.015745  ...  0.057286 -0.021680 -0.040389   \n",
       "3    -0.045075 -0.045403 -0.019771  ...  0.064901 -0.031808 -0.035478   \n",
       "4    -0.051125 -0.038727 -0.013142  ...  0.067381 -0.025004 -0.037318   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1228 -0.054338 -0.046695 -0.021423  ...  0.071683 -0.026062 -0.039263   \n",
       "1229 -0.054856 -0.046236 -0.017079  ...  0.071391 -0.027886 -0.037365   \n",
       "1230 -0.054147 -0.047652 -0.024619  ...  0.071534 -0.028025 -0.037676   \n",
       "1231 -0.049178 -0.044158 -0.014196  ...  0.086611 -0.018506 -0.027007   \n",
       "1232 -0.062268 -0.041151 -0.007892  ...  0.073401 -0.014165 -0.040095   \n",
       "\n",
       "         p_506     p_507     p_508     p_509     p_510     p_511  target  \n",
       "0     0.012536  0.043216  0.084375  0.007837  0.069794 -0.044134  single  \n",
       "1     0.013370  0.073821  0.096903  0.017133  0.064631 -0.039452  single  \n",
       "2     0.014894  0.037244  0.083684  0.005021  0.065194 -0.036202  single  \n",
       "3     0.020381  0.035428  0.084140  0.008325  0.061186 -0.041064  single  \n",
       "4     0.013757  0.041707  0.090888  0.021773  0.070574 -0.041105  single  \n",
       "...        ...       ...       ...       ...       ...       ...     ...  \n",
       "1228  0.015930  0.054902  0.090228  0.004987  0.065474 -0.042609  double  \n",
       "1229  0.019784  0.049307  0.091884  0.014374  0.066112 -0.041239  double  \n",
       "1230  0.016719  0.061040  0.093330  0.009919  0.064024 -0.042506  double  \n",
       "1231  0.024811  0.059834  0.097593  0.028478  0.077590 -0.045125  double  \n",
       "1232  0.023925  0.065251  0.095360  0.009302  0.068400 -0.043873  double  \n",
       "\n",
       "[1233 rows x 513 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../encoded_data/single_double_dna_fasttext.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"target\"]\n",
    "X = df.drop(columns=[\"target\"])\n",
    "X_train, X_test, y_train, y_test = random_under_sampling_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_f1_score</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_confussion_matrix</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>train_f1_weighted</th>\n",
       "      <th>train_recall_weighted</th>\n",
       "      <th>train_precision_weighted</th>\n",
       "      <th>train_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.753731</td>\n",
       "      <td>0.745759</td>\n",
       "      <td>0.806100</td>\n",
       "      <td>0.753731</td>\n",
       "      <td>[[61, 3], [30, 40]]</td>\n",
       "      <td>0.033622</td>\n",
       "      <td>0.035018</td>\n",
       "      <td>0.670444</td>\n",
       "      <td>0.691574</td>\n",
       "      <td>0.746061</td>\n",
       "      <td>0.691574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.783582</td>\n",
       "      <td>0.783642</td>\n",
       "      <td>0.785887</td>\n",
       "      <td>0.783582</td>\n",
       "      <td>[[52, 12], [17, 53]]</td>\n",
       "      <td>0.019146</td>\n",
       "      <td>0.066191</td>\n",
       "      <td>0.768646</td>\n",
       "      <td>0.773920</td>\n",
       "      <td>0.794870</td>\n",
       "      <td>0.773920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GaussianProcessClassifier</td>\n",
       "      <td>0.805970</td>\n",
       "      <td>0.805538</td>\n",
       "      <td>0.814172</td>\n",
       "      <td>0.805970</td>\n",
       "      <td>[[56, 8], [18, 52]]</td>\n",
       "      <td>0.286896</td>\n",
       "      <td>0.090676</td>\n",
       "      <td>0.751084</td>\n",
       "      <td>0.753549</td>\n",
       "      <td>0.763007</td>\n",
       "      <td>0.753549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.783582</td>\n",
       "      <td>0.781934</td>\n",
       "      <td>0.787524</td>\n",
       "      <td>0.783582</td>\n",
       "      <td>[[45, 19], [10, 60]]</td>\n",
       "      <td>0.010116</td>\n",
       "      <td>0.015281</td>\n",
       "      <td>0.701790</td>\n",
       "      <td>0.706235</td>\n",
       "      <td>0.719683</td>\n",
       "      <td>0.706235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.738806</td>\n",
       "      <td>0.738704</td>\n",
       "      <td>0.738684</td>\n",
       "      <td>0.738806</td>\n",
       "      <td>[[46, 18], [17, 53]]</td>\n",
       "      <td>0.148732</td>\n",
       "      <td>0.018234</td>\n",
       "      <td>0.703033</td>\n",
       "      <td>0.703858</td>\n",
       "      <td>0.707575</td>\n",
       "      <td>0.703858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.835821</td>\n",
       "      <td>0.835821</td>\n",
       "      <td>0.835821</td>\n",
       "      <td>0.835821</td>\n",
       "      <td>[[53, 11], [11, 59]]</td>\n",
       "      <td>0.751581</td>\n",
       "      <td>0.012879</td>\n",
       "      <td>0.771125</td>\n",
       "      <td>0.773704</td>\n",
       "      <td>0.785490</td>\n",
       "      <td>0.773704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.813433</td>\n",
       "      <td>0.813485</td>\n",
       "      <td>0.813628</td>\n",
       "      <td>0.813433</td>\n",
       "      <td>[[52, 12], [13, 57]]</td>\n",
       "      <td>0.482951</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.795135</td>\n",
       "      <td>0.796019</td>\n",
       "      <td>0.801517</td>\n",
       "      <td>0.796019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.850746</td>\n",
       "      <td>0.850746</td>\n",
       "      <td>0.854164</td>\n",
       "      <td>0.850746</td>\n",
       "      <td>[[57, 7], [13, 57]]</td>\n",
       "      <td>0.172067</td>\n",
       "      <td>0.015442</td>\n",
       "      <td>0.822975</td>\n",
       "      <td>0.823395</td>\n",
       "      <td>0.826015</td>\n",
       "      <td>0.823395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>0.745700</td>\n",
       "      <td>0.746470</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>[[45, 19], [15, 55]]</td>\n",
       "      <td>1.215263</td>\n",
       "      <td>0.019042</td>\n",
       "      <td>0.731048</td>\n",
       "      <td>0.731420</td>\n",
       "      <td>0.732460</td>\n",
       "      <td>0.731420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>[[55, 9], [9, 61]]</td>\n",
       "      <td>6.014656</td>\n",
       "      <td>0.012352</td>\n",
       "      <td>0.792933</td>\n",
       "      <td>0.793611</td>\n",
       "      <td>0.796583</td>\n",
       "      <td>0.793611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  description  test_accuracy  test_f1_score  test_precision  \\\n",
       "0                         SVC       0.753731       0.745759        0.806100   \n",
       "1        KNeighborsClassifier       0.783582       0.783642        0.785887   \n",
       "2   GaussianProcessClassifier       0.805970       0.805538        0.814172   \n",
       "3                  GaussianNB       0.783582       0.781934        0.787524   \n",
       "4      DecisionTreeClassifier       0.738806       0.738704        0.738684   \n",
       "5           BaggingClassifier       0.835821       0.835821        0.835821   \n",
       "6      RandomForestClassifier       0.813433       0.813485        0.813628   \n",
       "7        ExtraTreesClassifier       0.850746       0.850746        0.854164   \n",
       "8          AdaBoostClassifier       0.746269       0.745700        0.746470   \n",
       "9  GradientBoostingClassifier       0.865672       0.865672        0.865672   \n",
       "\n",
       "   test_recall test_confussion_matrix  fit_time  score_time  \\\n",
       "0     0.753731    [[61, 3], [30, 40]]  0.033622    0.035018   \n",
       "1     0.783582   [[52, 12], [17, 53]]  0.019146    0.066191   \n",
       "2     0.805970    [[56, 8], [18, 52]]  0.286896    0.090676   \n",
       "3     0.783582   [[45, 19], [10, 60]]  0.010116    0.015281   \n",
       "4     0.738806   [[46, 18], [17, 53]]  0.148732    0.018234   \n",
       "5     0.835821   [[53, 11], [11, 59]]  0.751581    0.012879   \n",
       "6     0.813433   [[52, 12], [13, 57]]  0.482951    0.015152   \n",
       "7     0.850746    [[57, 7], [13, 57]]  0.172067    0.015442   \n",
       "8     0.746269   [[45, 19], [15, 55]]  1.215263    0.019042   \n",
       "9     0.865672     [[55, 9], [9, 61]]  6.014656    0.012352   \n",
       "\n",
       "   train_f1_weighted  train_recall_weighted  train_precision_weighted  \\\n",
       "0           0.670444               0.691574                  0.746061   \n",
       "1           0.768646               0.773920                  0.794870   \n",
       "2           0.751084               0.753549                  0.763007   \n",
       "3           0.701790               0.706235                  0.719683   \n",
       "4           0.703033               0.703858                  0.707575   \n",
       "5           0.771125               0.773704                  0.785490   \n",
       "6           0.795135               0.796019                  0.801517   \n",
       "7           0.822975               0.823395                  0.826015   \n",
       "8           0.731048               0.731420                  0.732460   \n",
       "9           0.792933               0.793611                  0.796583   \n",
       "\n",
       "   train_accuracy  \n",
       "0        0.691574  \n",
       "1        0.773920  \n",
       "2        0.753549  \n",
       "3        0.706235  \n",
       "4        0.703858  \n",
       "5        0.773704  \n",
       "6        0.796019  \n",
       "7        0.823395  \n",
       "8        0.731420  \n",
       "9        0.793611  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_model = ClfModel(X_train, y_train, X_test, y_test)\n",
    "clf_model.make_exploration()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peptitools_backend_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
